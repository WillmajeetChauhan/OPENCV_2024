{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f9a7ad-1265-42aa-8a68-6a434a5c73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b050d552-241a-4341-8618-bad227279e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour moments( provide proper info.about area on which contour is build)\n",
    "#convex hull (tell min.contour ofthe object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1973b5-9a30-4d4e-9ac9-4a5723c9c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour moment\n",
    "img = cv2.imread(\"shap.jpg\")\n",
    "\n",
    "gry = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_,thr = cv2.threshold(gry,205,255,cv2.THRESH_BINARY)\n",
    "\n",
    "cnt,hir = cv2.findContours(thr,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)  # TO FIND THE CONTOUR\n",
    "\n",
    "#img = cv2.drawContours(img,cnt,-1,(0,0,255),4)  # to apply contour on current image\n",
    "\n",
    "ar = []\n",
    "for c in cnt:\n",
    "    m = cv2.moments(c)\n",
    "    x = int(m[\"m10\"]/m[\"m00\"])\n",
    "    y = int(m[\"m01\"]/m[\"m00\"])\n",
    "    cv2.drawContours(img,cnt,-1,(0,0,255),4)\n",
    "    cv2.circle(img,(x,y),5,(255,0,0),-1)\n",
    "    a = cv2.contourArea(c)\n",
    "    ar.append(a)\n",
    "print(ar)\n",
    "cv2.imshow(\"thre\",thr)\n",
    "cv2.imshow(\"willma\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d23e954f-b570-4ab2-a929-f5cbf3d3ab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[358801.0, 29735.5, 26761.5, 12945.0, 10552.0, 29390.5, 27172.5, 26769.5, 24289.5, 23790.0, 21526.0, 31349.0, 28900.0]\n"
     ]
    }
   ],
   "source": [
    "# convex hull\n",
    "\n",
    "img = cv2.imread(\"shap.jpg\")\n",
    "\n",
    "gry = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_,thr = cv2.threshold(gry,205,255,cv2.THRESH_BINARY)\n",
    "\n",
    "cnt,hir = cv2.findContours(thr,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)  # TO FIND THE CONTOUR\n",
    "\n",
    "#img = cv2.drawContours(img,cnt,-1,(0,0,255),4)  # to apply contour on current image\n",
    "\n",
    "ar = []\n",
    "for c in cnt:\n",
    "    m = cv2.moments(c)\n",
    "    x = int(m[\"m10\"]/m[\"m00\"])\n",
    "    y = int(m[\"m01\"]/m[\"m00\"])\n",
    "    cv2.drawContours(img,cnt,-1,(0,0,255),4)\n",
    "    cv2.circle(img,(x,y),5,(255,0,0),-1)\n",
    "    a = cv2.contourArea(c)\n",
    "    ar.append(a)\n",
    "    ep = 0.01*cv2.arcLength(c,True)  # cal.the max.len of arc of area of contour.\n",
    "    d =  cv2.approxPolyDP(c,ep,True)    # plot the above detail.\n",
    "    h = cv2.convexHull(d) # make the convex hull\n",
    "# 4 points are needed for convex hull\n",
    "    x,y,w,h = cv2.boundingRect(h)\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+w),(0,255,0),5)\n",
    "\n",
    "print(ar)\n",
    "cv2.imshow(\"thre\",thr)\n",
    "cv2.imshow(\"willma\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c01e0b16-93dc-405b-aa72-4fb1860adcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object detection using contour.\n",
    "def willma(x): # scaling pases from a parameter which passesfrom function which gives nothing.\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"prachi\")\n",
    "cv2.createTrackbar(\"th\",\"prachi\",0,255,willma)\n",
    "\n",
    "cv2.createTrackbar(\"lb\",\"prachi\",0,255,willma)\n",
    "cv2.createTrackbar(\"lg\",\"prachi\",0,255,wQillma)\n",
    "cv2.createTrackbar(\"lr\",\"prachi\",0,255,willma)\n",
    "\n",
    "cv2.createTrackbar(\"hb\",\"prachi\",255,255,willma)\n",
    "cv2.createTrackbar(\"hg\",\"prachi\",255,255,willma)\n",
    "cv2.createTrackbar(\"hr\",\"prachi\",255,255,willma)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    r,frame = cap.read()\n",
    "    if r == True:\n",
    "\n",
    "        thr = cv2.getTrackbarPos(\"th\",\"prachi\")\n",
    "\n",
    "        LB = cv2.getTrackbarPos(\"lb\",\"prachi\")\n",
    "        LG = cv2.getTrackbarPos(\"lg\",\"prachi\")\n",
    "        LR = cv2.getTrackbarPos(\"lr\",\"prachi\")\n",
    "\n",
    "        HB = cv2.getTrackbarPos(\"hb\",\"prachi\")\n",
    "        HG = cv2.getTrackbarPos(\"hg\",\"prachi\")\n",
    "        HR = cv2.getTrackbarPos(\"hr\",\"prachi\")\n",
    "\n",
    "        lower = np.array([LB,LG,LR])\n",
    "        upper = np.array([HB,HG,HR])\n",
    "\n",
    "        \n",
    "        frame = cv2.flip(frame,1)   # flip towards y- axis.\n",
    "        frame = cv2.resize(frame,(400,400))\n",
    "        hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        m = cv2.inRange(hsv,lower,upper)\n",
    "        result = cv2.bitwise_and(frame,frame,mask = m)\n",
    "        fr = cv2.bitwise_not(result)\n",
    "\n",
    "        _,thi = cv2.threshold(m,thr,255,cv2.THRESH_BINARY)\n",
    "        contour,hr = cv2.findContours(thi,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        cv2.drawContours(frame,contour,-1,(255,0,0),2)\n",
    "\n",
    "                            \n",
    "        cv2.imshow(\"thr\",thi)\n",
    "        cv2.imshow(\"res\",result)\n",
    "        cv2.imshow(\"mask\",m)\n",
    "       # cv2.imshow(\"hsv\",hsv)\n",
    "        cv2.imshow(\"wc\",frame)\n",
    "        if cv2.waitKey(25) & 0xff == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4973888-5d4b-4a15-ab99-0cc2b8af9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image background removal histogram\n",
    "\n",
    "img = cv2.imread(\"img2.jpg\")\n",
    "img = cv2.resize(img,(500,500))\n",
    "hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)    # TO CONVERT THE IMAGE IN HSV TYPE.\n",
    "\n",
    "img1 = cv2.imread(\"img56.jpg\")\n",
    "hsv2 = cv2.cvtColor(img1,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "hist =cv2.calcHist([hsv2],[0,1],None,[180,256],[0,150,0,256],) # passing all chanel,x-axis,y-axis.\n",
    "# img,channels,mask,histsize,ranges\n",
    "mask = cv2.calcBackProject([hsv],[0,1],hist,[0,150,0,256],1)  # scale\n",
    "\n",
    "\n",
    "ker = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))  # TO BUILD FILTER.\n",
    "# SHAPE,KSIZE\n",
    "mask = cv2.filter2D(mask,-1,ker)  # src,depth,kernel\n",
    "\n",
    "boolean,thr = cv2.threshold(mask,230,255,cv2.THRESH_BINARY)   # CONVERT INTO BINARY IMAGE.\n",
    "# src,thresh value,max. value,type\n",
    "\n",
    "mask = cv2.merge((mask,mask,mask))\n",
    "\n",
    "res = cv2.bitwise_or(img,mask)\n",
    "\n",
    "cv2.imshow(\"willmajeet\",res)\n",
    "cv2.imshow(\"willmajeet1\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37261e6-5359-43bc-97b7-65240ebb4944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no lines were detected\n"
     ]
    }
   ],
   "source": [
    "# hough transformation lines.  ( to build lines over images)\n",
    "img = cv2.imread(\"img90.png\")\n",
    "gry = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edg = cv2.Canny(gry,20,250)  # img, threshold1, 2  to detect edge\n",
    "\n",
    "lines = cv2.HoughLinesP(edg , 1 ,np.pi/180 , 200 , minLineLength=50 , maxLineGap=10)\n",
    "if lines is not None:\n",
    "   for r,th in lines[0]:\n",
    "       a = np.cos(th)    \n",
    "       b = np.sin(th)\n",
    "\n",
    "       x0 = a*r\n",
    "       y0 = b*r\n",
    "\n",
    "       x1 = int(x0+1000*(-b))\n",
    "       y1 = int(y0+1000*(a))\n",
    "       x2 = int(x0-1000*(-b))\n",
    "       y2 = int(y0-1000*(a))\n",
    "\n",
    "       cv2.line(img,(x1,y1),(x2,y2),(0,255,0))\n",
    "else:\n",
    "    print(\"no lines were detected\")\n",
    "    \n",
    "cv2.imshow(\"willma\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15485b9-0cb1-4368-a664-140dd379c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img90.png\")\n",
    "gry = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edg = cv2.Canny(gry, 20, 250)  # Perform Canny edge detection\n",
    "\n",
    "# Use HoughLinesP for probabilistic line detection\n",
    "lines = cv2.HoughLinesP(edg, 1, np.pi / 180, 100, minLineLength=50, maxLineGap=10)\n",
    "print(lines)\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "else:\n",
    "    print(\"No lines were detected.\")\n",
    "\n",
    "cv2.imshow(\"willma\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dff3081-c7c2-410a-9683-6a690d22eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template matching using opencv\n",
    "img = cv2.imread(\"img100.jpg\")\n",
    "gry = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "tmp = cv2.imread(\"img101.jpg\")\n",
    "gry1 = cv2.cvtColor(tmp,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#print(gry1.shape)\n",
    "w,h = gry1.shape[::-1]  #to use all rows and columns of the gray1 img.\n",
    "\n",
    "res = cv2.matchTemplate(gry,gry1,cv2.TM_CCORR_NORMED) # TO MATCH THE SMALL IMG FROM BIGGER ONE.\n",
    "\n",
    "thr = 0.99\n",
    "\n",
    "l = np.where(res>=thr) #  to get gry1 img. in img. and outlined by a certain shape.\n",
    "#print(l)  #array of our tmp has got.\n",
    "for i in zip(*l[::-1]):\n",
    "    cv2.rectangle(img,i,(i[0]+w,i[1]+h),(0,0,255),2) # img,pt1,pt2,colour,thickness\n",
    "\n",
    "\n",
    "#print(res) # print points of dark blur img.\n",
    "img = cv2.resize(img,(600,500))\n",
    "#cv2.imshow(\"willma2\",res)\n",
    "cv2.imshow(\"willma\",img)\n",
    "cv2.imshow(\"willma1\",tmp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ebf67d8-fc1a-4df1-a021-5d8b1b124304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 348)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w,h = gry1.shape[::-1]\n",
    "w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0788b9b0-3918-4b0f-becc-95fc11714f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[238.5 132.5  34.4]\n",
      "  [ 89.5 121.5  33.6]\n",
      "  [123.5  90.5  31.1]\n",
      "  [100.5  54.5  27.7]\n",
      "  [173.5 114.5  32. ]\n",
      "  [197.5  29.5  25.8]\n",
      "  [ 27.5  96.5  29.4]\n",
      "  [235.5  72.5  30.7]\n",
      "  [174.5  53.5  49. ]\n",
      "  [ 51.5  70.5  34.3]\n",
      "  [ 74.5  68.5  25.2]]]\n"
     ]
    }
   ],
   "source": [
    "# Hough cicle detection.\n",
    "img = cv2.imread(\"img103.jpeg\")\n",
    "gr = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gr = cv2.medianBlur(gr,5) # kernelsize\n",
    "\n",
    "c = cv2.HoughCircles(gr,cv2.HOUGH_GRADIENT,1,20,param1=80, param2=34,minRadius=0, maxRadius=0)\n",
    "#(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius\n",
    "print(c)\n",
    "\n",
    "data = np.uint16(np.around(c))  # roundfigure all data of circle.\n",
    "\n",
    "for (x,y,r) in data[0,:]:\n",
    "    cv2.circle(img,(x,y),r,(0,0,255),4)\n",
    "#(img, center, radius, color[, thickness[, lineType\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"willma\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69934879-7ade-463c-b6d0-4db17d2e2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabcut algorithm for background change.  ( remove background)\n",
    "img = cv2.imread(\"img110.jpeg\")\n",
    "\n",
    "mask1 = np.zeros(img.shape[:2],np.uint8)\n",
    "\n",
    "bgmask = np.zeros((1,65),np.float64)*255\n",
    "fgmask = np.zeros((1,65),np.float64)*255\n",
    "\n",
    "# x1,y1,x2,y2.\n",
    "r = [24,16,251,173]\n",
    "cv2.grabCut(img,mask1,r,bgmask,fgmask,10,cv2.GC_INIT_WITH_RECT)\n",
    "#(img, mask, rect, bgdModel, fgdModel, iterCount[, mode]) -> mask, bgdModel, fgdModel\n",
    "\n",
    "mask2 = np.where((mask1 ==2)|(mask1 == 0),0,1).astype(\"uint8\")\n",
    "\n",
    "img = img*mask2[:,:,np.newaxis] \n",
    "\n",
    "\n",
    "cv2.imshow(\"wilma\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13ab8bfb-4126-4d35-becf-306fe2f68df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video background removal using algo.\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\HP LAPTOP-PC\\Desktop\\DRDO Project\\running.mp4\")\n",
    "\n",
    "algo1 = cv2.createBackgroundSubtractorKNN(detectShadows = True)\n",
    "algo2 = cv2.createBackgroundSubtractorMOG2(detectShadows = True)\n",
    "\n",
    "while True:\n",
    "    r,f = cap.read()\n",
    "    if r == True:\n",
    "        f = cv2.resize(f,(500,500))\n",
    "        r1 = algo1.apply(f)\n",
    "        r2 = algo2.apply(f)\n",
    "        cv2.imshow(\"algo1\",r1)\n",
    "        cv2.imshow(\"algo2\",r2)\n",
    "        cv2.imshow(\"willma\",f)\n",
    "        if cv2.waitKey(40) & 0xff == ord(\"p\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "77e01867-0520-4b9c-92aa-cb3c756461a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object tracking and detection.\n",
    "cap =cv2.VideoCapture(r\"C:\\Users\\HP LAPTOP-PC\\Desktop\\video2.mp4\")\n",
    "\n",
    "# ROI PORTION\n",
    "r,f = cap.read() # capture image from video\n",
    "x,y,w,h = 130, 110, 510, 900# 4 coordinates of image \n",
    "t = (x,y,w,h)  # ROI\n",
    "roi = f[y:y+h,x:x+w]  # to extract region of interest of image from video\n",
    "hsv_roi = cv2.cvtColor(roi,cv2.COLOR_BGR2HSV) # convert frame in hsv format\n",
    "mask = cv2.inRange(hsv_roi,np.array((0.,60.,32.)),np.array((180.,255.,255.)))\n",
    "#(src, lowerb, upperb[, dst])\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180]) # mask applied over histogram which filter it to get the image.\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)  # to normalize the data.\n",
    "#(src, dst[, alpha[, beta[, norm_type[, dtype[, mask]]]]])\n",
    "cv2.imshow(\"willma\",roi)\n",
    "\n",
    "# to implement roi on real video.\n",
    "tr = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    r,f = cap.read()\n",
    "    if r == True:\n",
    "        f = cv2.resize(f,(500,500))\n",
    "        hsv_f = cv2.cvtColor(f,cv2.COLOR_BGR2HSV)\n",
    "        d = cv2.calcBackProject([hsv_f],[0],roi_hist,[0,180],1)  # roi img overlapped with frames of video then search for roi img in video .\n",
    "        boolean,tracking = cv2.meanShift(d,t,tr)  # shift the roi images according to the position in the video.\n",
    "        #boolean,tracking = cv2.CamShift(d,t,tr) \n",
    "        # probImage, window, criteria\n",
    "        x,y,w,h = tracking # new coordinates of image where it moves.\n",
    "        final = cv2.rectangle(f,(x,y),(x+w,y+h),(0,0,255),4)\n",
    "        cv2.imshow(\"willma\",final)\n",
    "        if cv2.waitKey(25) & 0xff == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7260a4a-06ff-4631-80fd-bb64433ffbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
